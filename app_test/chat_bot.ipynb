{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINE_CONE_API_KEY = \"aaab20a3-08ea-4b22-9e4a-2d1316049892\"\n",
    "PINE_CONE_ENV = \"gcp-starter\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the PDF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data from PDF file\n",
    "def data_extractor(dir_path):\n",
    "    loader = DirectoryLoader(dir_path, # directory path\n",
    "                            glob=\"*.pdf\", # only pdf files\n",
    "                            loader_cls = PyPDFLoader, # using module\n",
    "                            show_progress=True,\n",
    "                            use_multithreading=True\n",
    "                            )\n",
    "    # loading the pdf documents\n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:26<00:00, 26.02s/it]\n"
     ]
    }
   ],
   "source": [
    "pdf_data = data_extractor('data/')\n",
    "# print(pdf_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting corpus into text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text chunks\n",
    "def text_splitter(document):\n",
    "    text_chunks = RecursiveCharacterTextSplitter(chunk_size=500,\n",
    "                                    chunk_overlap = 20\n",
    "                                )\n",
    "    return text_chunks.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text chunks :  7020\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_splitter(pdf_data)\n",
    "print('Length of text chunks : ',len(text_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting text to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elava\\anaconda3\\envs\\medical_chat_bot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      ".gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 167kB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 31.3kB/s]\n",
      "README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 1.25MB/s]\n",
      "config.json: 100%|██████████| 612/612 [00:00<00:00, 59.7kB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 11.5kB/s]\n",
      "data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 2.17MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:05<00:00, 17.9MB/s]\n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 3.58kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 9.56kB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 1.26MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 350/350 [00:00<?, ?B/s] \n",
      "train_script.py: 100%|██████████| 13.2k/13.2k [00:00<00:00, 3.79MB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 13.6MB/s]\n",
      "modules.json: 100%|██████████| 349/349 [00:00<00:00, 28.5kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Downloading the embedding model from hugging face\n",
    "EMBD_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=EMBD_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the vector DB pinecone\n",
    "pinecone.init(api_key=PINE_CONE_API_KEY,\n",
    "              environment=PINE_CONE_ENV\n",
    "            )\n",
    "index_name = \"medical-chat-bot-llama-2\"\n",
    "\n",
    "# creating embeddings for each text chunk and storing into pinecone\n",
    "doc_search = Pinecone.from_texts([i.page_content for i in text_chunks], # list of chunks text\n",
    "                                  embedding_model, # Embedding model \n",
    "                                  index_name = index_name  # pinecone index name\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical_chat_bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
